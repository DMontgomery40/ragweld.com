# ragweld

> Open-source RAG workbench with tribrid retrieval (vector + sparse + graph), trainable LoRA reranking, embedded Grafana observability, and a visual configuration wizard. MIT licensed.

ragweld makes RAG pipelines visible and controllable. Instead of black-box APIs or framework code, you get a GUI where you can see every retrieval stage, tune 396 parameters through a wizard, train a domain-specific reranker from user feedback, and monitor everything through embedded Grafana dashboards.

## Core Concepts

- [Tribrid Retrieval](https://ragweld.com/glossary/): Combines dense vector search (Qdrant), sparse lexical search (BM25/Redis), and knowledge graph traversal (Neo4j) into a single pipeline with configurable fusion weights.
- [Trainable LoRA Reranker](https://ragweld.com/blog/posts/learning-reranker-qwen3-mlx/): Fine-tunes a lightweight reranker on your domain data using thumbs-up/down feedback. Runs on Apple Silicon via MLX or GPU via PyTorch.
- [Evaluation Framework](https://ragweld.com/glossary/eval-dataset-path/): Built-in eval with golden datasets, run diffs, regression detection, and drilldowns per query.
- [Embedded Observability](https://ragweld.com/glossary/grafana-url/): Grafana dashboards embedded in split-view alongside the chat interface. See latency, token usage, retrieval scores in real time.
- [Chat Memory with RAG Hybrid Mode](https://ragweld.com/blog/posts/when-to-query-chat-memory-vs-your-corpus/): Smart gating decides when to query conversation history, the corpus, or both.

## Documentation

- [Live Demo](https://ragweld.com/demo/): Interactive demo of the full ragweld interface.
- [Parameter Glossary](https://ragweld.com/glossary/): Searchable reference for all 396 RAG configuration parameters with descriptions, categories, and links.
- [Full Documentation](https://dmontgomery40.github.io/ragweld/latest/configuration/): Technical docs hosted on GitHub Pages.
- [GitHub Repository](https://github.com/DMontgomery40/ragweld): Source code (MIT license).

## Blog

- [Qwen3 LoRA Learning Reranker on Apple Silicon](https://ragweld.com/blog/posts/learning-reranker-qwen3-mlx/): How ragweld trains and serves a Qwen3 yes/no-logit reranker with MLX on Apple Silicon.
- [When to Query Chat Memory vs. Your Corpus](https://ragweld.com/blog/posts/when-to-query-chat-memory-vs-your-corpus/): Practical retrieval policy for deciding when to hit chat memory, when to hit the corpus, and how to avoid token/latency blowups at scale.

## Architecture

ragweld is a Python backend (FastAPI) with a React frontend (Vite). Key infrastructure:

- **Vector store**: Qdrant (dense embeddings via OpenAI, Voyage, Ollama, or custom)
- **Sparse store**: Redis (BM25 tokenization with configurable stop words)
- **Graph store**: Neo4j (entity/relationship extraction, graph traversal for multi-hop queries)
- **Reranker**: LoRA fine-tuned model (Qwen3-0.6B default) trained from user feedback triplets
- **Observability**: Embedded Grafana with pre-built RAG dashboards
- **Config**: 396 parameters managed through Pydantic models, exposed via 5-step setup wizard

## API

The ragweld API is RESTful (FastAPI with OpenAPI docs at `/docs`). Key endpoints:

- `POST /query` — Run a retrieval query with configurable pipeline stages
- `POST /index` — Index documents (supports code repos, PDFs, markdown)
- `POST /eval/run` — Execute evaluation against golden dataset
- `GET /config` — Read current configuration
- `PUT /config` — Update configuration parameters
- `POST /reranker/train` — Trigger reranker fine-tuning from feedback data

## Pricing

- **Self-hosted**: Free forever (MIT license)
- **Hosted Solo**: $149/month (managed infrastructure, priority support)
- **Hosted Team**: $399/month (team features, shared dashboards, SSO)
- **Enterprise**: Custom pricing (on-prem deployment, SLAs, dedicated support)
